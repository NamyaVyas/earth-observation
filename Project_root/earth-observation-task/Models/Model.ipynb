{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1e7c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, models\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from torchmetrics.classification import MulticlassF1Score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7743fb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41df7123",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 128\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS = 10\n",
    "PLOT_DIR = \"C:/Users/Namya/JobScreenTask/Project_root/venv_313/earth-observation-task/Scripts/plots\"\n",
    "os.makedirs(PLOT_DIR, exist_ok=True)\n",
    "DEVICE = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd48a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../train.csv\")\n",
    "test_df = pd.read_csv(\"../test.csv\")\n",
    "\n",
    "# Map labels to integers\n",
    "labels = sorted(train_df['label'].unique())\n",
    "label2idx = {label: idx for idx, label in enumerate(labels)}\n",
    "idx2label = {idx: label for label, idx in label2idx.items()}\n",
    "train_df['label_idx'] = train_df['label'].map(label2idx)\n",
    "test_df['label_idx'] = test_df['label'].map(label2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3a619e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7a6d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CachedDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        self.cache = []\n",
    "        for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Caching images\"):\n",
    "            img = Image.open(row['file']).convert(\"RGB\")\n",
    "            self.cache.append(img)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = self.cache[idx]\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        label = self.df.iloc[idx]['label_idx']\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b228d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SatelliteDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = Image.open(row['file']).convert(\"RGB\")\n",
    "        img = transform(img)   # use the defined transform\n",
    "        label = row['label_idx']\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a199df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    CachedDataset(train_df, transform=transform),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    CachedDataset(test_df, transform=transform),\n",
    "    batch_size=1,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "model = models.resnet18(pretrained=False, num_classes=len(labels))\n",
    "model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "model.maxpool = nn.Identity()\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31056ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "dataset = SatelliteDataset(train_df, transform=transform)\n",
    "for i in tqdm(range(len(dataset))):\n",
    "    img, label = dataset[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb10b16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "print(\"\\n Starting training…\\n\")\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_idx, (imgs, targets) in enumerate(train_loader):\n",
    "        imgs, targets = imgs.to(DEVICE), targets.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS}] Loss: {total_loss/len(train_loader):.4f}\")\n",
    "print(f\" Epoch [{epoch+1}/{EPOCHS}] Avg Loss: {total_loss/len(train_loader):.4f}\")\n",
    "print(\"\\n Training complete. Starting evaluation…\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f936784d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "model.eval()\n",
    "y_true, y_pred = [], []\n",
    "with torch.no_grad():\n",
    "    for imgs, targets in test_loader:\n",
    "        imgs, targets = imgs.to(DEVICE), targets.to(DEVICE)\n",
    "        outputs = model(imgs)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        y_true.append(targets.item())\n",
    "        y_pred.append(preds.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632d194a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom F1\n",
    "f1_custom = f1_score(y_true, y_pred, average='weighted')\n",
    "print(f\"Custom F1 score (sklearn): {f1_custom:.4f}\")\n",
    "\n",
    "# Torchmetrics F1\n",
    "tm_f1 = MulticlassF1Score(num_classes=len(labels), average='weighted').to(DEVICE)\n",
    "y_true_tensor = torch.tensor(y_true).to(DEVICE)\n",
    "y_pred_tensor = torch.tensor(y_pred).to(DEVICE)\n",
    "f1_torchmetrics = tm_f1(y_pred_tensor, y_true_tensor).item()\n",
    "print(f\"Torchmetrics F1 score: {f1_torchmetrics:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1514fbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(PLOT_DIR, \"confusion_matrix.png\"))\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "print(f\"Confusion matrix plot saved: {PLOT_DIR}/confusion_matrix.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72337c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 correct & 5 incorrect\n",
    "correct = [i for i, (p,t) in enumerate(zip(y_pred,y_true)) if p==t][:5]\n",
    "incorrect = [i for i, (p,t) in enumerate(zip(y_pred,y_true)) if p!=t][:5]\n",
    "test_df = test_df.reset_index()\n",
    "\n",
    "fig, axes = plt.subplots(2,5, figsize=(20,8))\n",
    "for ax, idx in zip(axes[0], correct):\n",
    "    img = plt.imread(test_df.loc[idx, 'file'])\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(f\"True: {test_df.loc[idx,'label']}\\nPred: {test_df.loc[idx,'label']}\")\n",
    "    ax.axis('off')\n",
    "for ax, idx in zip(axes[1], incorrect):\n",
    "    img = plt.imread(test_df.loc[idx, 'file'])\n",
    "    pred_lbl = idx2label[y_pred[idx]]\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(f\"True: {test_df.loc[idx,'label']}\\nPred: {pred_lbl}\")\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(PLOT_DIR, \"correct_incorrect_examples.png\"))\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "print(f\"Correct & incorrect examples plot saved: {PLOT_DIR}/correct_incorrect_examples.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_313",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
